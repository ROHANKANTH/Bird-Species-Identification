{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bird Species Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              25089000  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 9009      \n",
      "=================================================================\n",
      "Total params: 39,812,697\n",
      "Trainable params: 25,098,009\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "Found 268 images belonging to 9 classes.\n",
      "Found 268 images belonging to 9 classes.\n",
      "9\n",
      "9\n",
      "Epoch 1/5\n",
      "9/9 [==============================] - 591s 66s/step - loss: 10.5592 - acc: 0.1828 - val_loss: 5.1176 - val_acc: 0.2687\n",
      "Epoch 2/5\n",
      "9/9 [==============================] - 488s 54s/step - loss: 3.0443 - acc: 0.3582 - val_loss: 0.8071 - val_acc: 0.6418\n",
      "Epoch 3/5\n",
      "9/9 [==============================] - 479s 53s/step - loss: 1.3151 - acc: 0.6082 - val_loss: 0.4158 - val_acc: 0.7052\n",
      "Epoch 4/5\n",
      "9/9 [==============================] - 478s 53s/step - loss: 0.7369 - acc: 0.7313 - val_loss: 0.5207 - val_acc: 0.8619\n",
      "Epoch 5/5\n",
      "9/9 [==============================] - 434s 48s/step - loss: 0.4673 - acc: 0.8433 - val_loss: 0.3569 - val_acc: 0.9142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# re-size all the images to this\n",
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "train_path = 'G:\\DATASET\\Images'\n",
    "valid_path = 'G:\\DATASET\\Images'\n",
    "\n",
    "# add preprocessing layer to the front of VGG\n",
    "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "# don't train existing weights\n",
    "for layer in vgg.layers:\n",
    "  layer.trainable = False\n",
    "  \n",
    "\n",
    "  \n",
    " # useful for getting number of classes\n",
    "folders = glob('G:\\DATASET\\Images\\*')\n",
    "\n",
    "  \n",
    "\n",
    "# our layers\n",
    "x = Flatten()(vgg.output)\n",
    "\n",
    "prediction = Dense(len(folders), activation='softmax')(x)\n",
    "\n",
    "# create a model object\n",
    "model = Model(inputs=vgg.input, outputs=prediction)\n",
    "\n",
    "# view the structure of the model\n",
    "model.summary()\n",
    "\n",
    "# tell the model what cost and optimization method to use\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['acc']\n",
    ")\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('G:\\DATASET\\Images',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode='categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('G:\\DATASET\\Images',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')\n",
    "\n",
    "\n",
    "print(len(training_set))\n",
    "print(len(test_set))\n",
    "# fit the model\n",
    "r = model.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=5,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set),\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "model.save('facefeatures_new_model.h5')w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_generator = train_datagen.flow_from_dataframe(test,directory='G:\\DATASET\\Test',x_col = 'Image',\n",
    "                 y_col = None,target_size=(224,224),class_mode = None,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x=model.predict(test_generator) \n",
    "test_x=np.array(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.42399194e-05, 1.61943876e-06, 7.79175878e-01, 6.19171351e-06,\n",
       "        1.07124761e-05, 1.54219947e-06, 6.68425419e-05, 1.55044962e-02,\n",
       "        2.05218449e-01],\n",
       "       [1.76869332e-06, 2.04231264e-06, 3.37020168e-03, 2.07248522e-05,\n",
       "        6.67900968e-05, 2.11667102e-05, 7.23700214e-05, 3.58983903e-04,\n",
       "        9.96086001e-01],\n",
       "       [6.87570637e-03, 4.09215834e-04, 1.08858414e-01, 3.41501758e-02,\n",
       "        7.16322362e-02, 8.06160830e-03, 1.54545745e-02, 5.85629046e-03,\n",
       "        7.48701751e-01],\n",
       "       [1.14405602e-05, 1.16908086e-04, 6.92311078e-02, 1.05238702e-04,\n",
       "        7.22834666e-05, 7.83508076e-05, 6.17498416e-04, 2.14746315e-03,\n",
       "        9.27619755e-01],\n",
       "       [1.24505605e-03, 9.14837525e-04, 3.82199176e-02, 9.28205326e-02,\n",
       "        1.05475197e-02, 6.90984773e-03, 1.43842092e-02, 7.66752958e-02,\n",
       "        7.58282840e-01],\n",
       "       [6.18177513e-03, 7.45000243e-01, 3.44593148e-03, 2.80807074e-02,\n",
       "        7.80771673e-02, 6.13715313e-02, 1.31835919e-02, 6.24148324e-02,\n",
       "        2.24424247e-03],\n",
       "       [8.71236902e-04, 2.69776268e-04, 1.15045339e-01, 1.97885558e-03,\n",
       "        3.10347648e-03, 5.20735863e-04, 4.98403609e-03, 2.84862190e-01,\n",
       "        5.88364303e-01],\n",
       "       [8.43620226e-02, 3.85628939e-02, 1.40134506e-02, 5.31324148e-01,\n",
       "        2.81153014e-03, 1.09802693e-01, 2.56244559e-02, 1.51618883e-01,\n",
       "        4.18799184e-02],\n",
       "       [2.20542960e-02, 7.57048046e-03, 2.15083058e-03, 1.77715067e-02,\n",
       "        3.03693991e-02, 2.74737120e-01, 4.15477566e-02, 1.56252846e-01,\n",
       "        4.47545737e-01],\n",
       "       [6.14757612e-02, 7.26187751e-02, 1.60439745e-01, 1.16657857e-02,\n",
       "        4.13305983e-02, 2.61887144e-02, 1.66873783e-02, 2.35840082e-02,\n",
       "        5.86009264e-01],\n",
       "       [7.54721314e-02, 2.54046202e-01, 1.13966234e-03, 5.07764556e-02,\n",
       "        4.34201630e-03, 1.27430744e-02, 1.31754279e-01, 1.49671808e-02,\n",
       "        4.54759061e-01],\n",
       "       [1.55659148e-03, 6.96818688e-06, 9.75988572e-04, 2.10753380e-04,\n",
       "        1.98296184e-05, 1.26229961e-05, 2.34714197e-03, 2.44298647e-03,\n",
       "        9.92427111e-01],\n",
       "       [5.74841619e-01, 1.27445534e-01, 9.75060510e-04, 1.01898685e-02,\n",
       "        7.72820413e-03, 5.56614064e-03, 1.92466125e-01, 1.64361298e-03,\n",
       "        7.91437700e-02],\n",
       "       [2.31804934e-05, 1.47930250e-05, 4.61892720e-04, 9.11103343e-05,\n",
       "        1.66898426e-05, 1.15514376e-05, 1.27271505e-03, 2.45537463e-04,\n",
       "        9.97862518e-01],\n",
       "       [1.35840446e-05, 1.25697425e-05, 4.98143882e-02, 7.03456826e-05,\n",
       "        5.19175548e-04, 1.45961123e-04, 1.23845486e-04, 9.82810464e-03,\n",
       "        9.39472079e-01],\n",
       "       [2.28324075e-06, 5.93297154e-05, 5.62164426e-01, 4.81908755e-05,\n",
       "        1.12397640e-04, 2.93948600e-04, 9.96086237e-05, 2.10674461e-02,\n",
       "        4.16152328e-01],\n",
       "       [3.47718084e-03, 4.83806798e-06, 6.79364324e-01, 1.84508134e-03,\n",
       "        2.16391272e-04, 9.79887118e-05, 2.48672673e-04, 2.44548600e-02,\n",
       "        2.90290564e-01],\n",
       "       [1.59570973e-05, 3.50892805e-07, 2.20384635e-03, 9.52383052e-05,\n",
       "        5.63245485e-05, 4.75370653e-05, 2.79774322e-05, 9.25970376e-01,\n",
       "        7.15823397e-02],\n",
       "       [4.64157611e-01, 9.01486166e-03, 9.25288768e-04, 6.09207600e-02,\n",
       "        3.71015258e-03, 1.07429447e-02, 4.01311576e-01, 4.22338396e-03,\n",
       "        4.49934453e-02],\n",
       "       [2.79162814e-05, 6.09179551e-05, 2.51785648e-04, 2.38420180e-05,\n",
       "        1.28438536e-04, 8.09344783e-05, 3.21282918e-04, 5.03378268e-03,\n",
       "        9.94071066e-01]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=np.argmax(test_x,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 8, 8, 8, 8, 1, 8, 3, 8, 8, 8, 8, 0, 8, 8, 2, 2, 7, 0, 8],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>TEST.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>test06.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>test1.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>test10.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>test11.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>test12.jpeg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>test13.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>test14.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>test15-16.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>test15.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>test17.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>test18.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>test19.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>test2.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>test3.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>test4.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>test5.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>test7.jpg</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>test8.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>test9.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Image  class\n",
       "0        TEST.jpg      2\n",
       "1      test06.jpg      8\n",
       "2       test1.jpg      8\n",
       "3      test10.jpg      8\n",
       "4      test11.jpg      8\n",
       "5     test12.jpeg      1\n",
       "6      test13.jpg      8\n",
       "7      test14.jpg      3\n",
       "8   test15-16.jpg      8\n",
       "9      test15.jpg      8\n",
       "10     test17.jpg      8\n",
       "11     test18.jpg      8\n",
       "12     test19.jpg      0\n",
       "13      test2.jpg      8\n",
       "14      test3.jpg      8\n",
       "15      test4.jpg      2\n",
       "16      test5.jpg      2\n",
       "17      test7.jpg      7\n",
       "18      test8.jpg      0\n",
       "19      test9.jpg      8"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "test=pd.DataFrame()\n",
    "test_image=os.listdir('G:\\DATASET\\Test')\n",
    "test['Image']=test_image\n",
    "test['class']=out\n",
    "test.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "plt.plot(r.history['loss'], label='train loss')\n",
    "plt.plot(r.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('LossVal_loss')\n",
    "\n",
    "# accuracies\n",
    "plt.plot(r.history['acc'], label='train acc')\n",
    "plt.plot(r.history['val_acc'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('AccVal_acc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
